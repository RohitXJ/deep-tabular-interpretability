"""
=====================================================
Deep Learning Interpretation & Visualization Module
=====================================================

This file contains the code logic for generating:
1. Training Loss Curves (To replace epoch text logs)
2. SHAP Interpretation Plots (Global Bar, Global Summary, Local Waterfall)

User: Gemini CLI
Project: Deep Learning Interpretability (DL Models Only)
"""

import matplotlib.pyplot as plt
import shap
import numpy as np

# ==============================================================================
# SECTION 1: TRAINING LOSS GRAPH (DL Models Only)
# ==============================================================================
"""
INSTRUCTION FOR FRONTEND INTEGRATION:
-------------------------------------
On the "Model Result Showing Page":
1. HIDE the raw textual logs of epoch-by-epoch training (e.g., "Epoch 1/50: Loss 0.5...").
2. Instead, DISPLAY the image generated by the function below.
3. After this image, display the standard model performance metrics (MSE/Accuracy, R2, etc.) as usual.
"""

def plot_training_loss(loss_history, model_name="Model"):
    """
    Generates a line chart showing how the model's loss decreased during training.
    
    Args:
        loss_history (list): A list of float values representing loss per epoch.
        model_name (str): Name of the model for the title (e.g., "ANN Deep Regression").
    """
    plt.figure(figsize=(10, 6))
    plt.plot(loss_history, label='Training Loss', color='#1f77b4', linewidth=2)
    plt.xlabel('Epochs', fontsize=12)
    plt.ylabel('Loss', fontsize=12)
    plt.title(f'{model_name} - Training Convergence', fontsize=14)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.legend()
    
    # Save this plot to a buffer or file to display on the frontend
    # plt.savefig("training_loss_curve.png") 
    plt.show()


# ==============================================================================
# SECTION 2: REGRESSION MODEL PLOTS
# ==============================================================================

def generate_regression_plots(shap_values_2d, features_data, features_unscaled, feature_names):
    """
    Generates interpretation plots for Regression models.
    
    Data Requirements:
    - shap_values_2d: A 2D numpy array of SHAP values (Shape: [n_samples, n_features]).
    - features_data: The SCALED input data used to calculate SHAP values (for Summary Plot color).
    - features_unscaled: The ORIGINAL (unscaled) data (for Waterfall Plot readability).
    - feature_names: List of strings representing column names.
    """
    
    # --- Plot 1: Global Feature Importance (Bar Plot) ---
    # Description: Shows the average absolute impact of each feature on the prediction.
    # Data: Uses the entire provided sample set.
    print("Generating Global Feature Importance (Bar Plot)...")
    shap.plots.bar(
        shap.Explanation(
            values=shap_values_2d, 
            data=features_data, 
            feature_names=feature_names
        ),
        show=False
    )
    plt.title("Top Features by Importance")
    plt.show()

    # --- Plot 2: Global Summary Plot (Beeswarm) ---
    # Description: Shows how feature values (high/low) affect predictions (push up/down).
    # Data: Uses the SCALED data for color coding (Red=High, Blue=Low).
    print("Generating Global Summary Plot...")
    shap.summary_plot(shap_values_2d, features_data, feature_names=feature_names)

    # --- Plot 3: Local Waterfall Plot ---
    # INSTRUCTION: Use UNSCALED data here so the user sees real values (e.g., "Age=25" instead of "Age=0.5").
    print("Generating Local Waterfall Plot (First Prediction)...")
    
    # Select the first sample [0]
    single_sample_values = shap_values_2d[0]
    single_sample_data = features_unscaled[0] # <--- IMPORTANT: Use Unscaled Data
    
    # Create explanation object for a single row
    exp_single = shap.Explanation(
        values=single_sample_values,
        base_values=0.0, # Replace with explainer.expected_value
        data=single_sample_data, 
        feature_names=feature_names
    )
    shap.plots.waterfall(exp_single)


# ==============================================================================
# SECTION 3: CLASSIFICATION MODEL PLOTS
# ==============================================================================

def generate_classification_plots(shap_values_2d, features_data, features_unscaled, feature_names):
    """
    Generates interpretation plots for Binary Classification models.
    
    Data Requirements:
    - shap_values_2d: 2D array for the *positive class* (Class 1). 
                      Ensure you select [0] from the list returned by explainer.shap_values().
    - features_data: SCALED input data.
    - features_unscaled: ORIGINAL (unscaled) input data.
    """

    # --- Plot 1: Global Feature Importance (Bar Plot) ---
    # Description: Shows which features drive the probability towards Class 1.
    print("Generating Global Feature Importance (Bar Plot)...")
    shap.plots.bar(
        shap.Explanation(
            values=shap_values_2d, 
            data=features_data, 
            feature_names=feature_names
        ),
        show=False
    )
    plt.title("Top Features driving Class 1 Prediction")
    plt.show()

    # --- Plot 2: Global Summary Plot (Beeswarm) ---
    # Description: Shows distribution of impact. 
    # Positive SHAP value = Pushes towards Class 1. Negative = Pushes towards Class 0.
    print("Generating Global Summary Plot...")
    shap.summary_plot(shap_values_2d, features_data, feature_names=feature_names)

    # --- Plot 3: Local Waterfall Plot ---
    # INSTRUCTION: Use UNSCALED data so users see real metric values (e.g., "Radius=15mm").
    print("Generating Local Waterfall Plot (First Prediction)...")
    
    single_sample_values = shap_values_2d[0]
    single_sample_data = features_unscaled[0] # <--- IMPORTANT: Use Unscaled Data
    
    exp_single_cls = shap.Explanation(
        values=single_sample_values,
        base_values=0.0, # Replace with explainer.expected_value[0]
        data=single_sample_data,
        feature_names=feature_names
    )
    shap.plots.waterfall(exp_single_cls)